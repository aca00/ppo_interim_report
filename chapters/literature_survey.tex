\chapter{Literature survey}

\section{Design principles for colloborative information seeking}

Websites are a great source of knowledge. These are areas in cyberspace where individuals with similar interests can come together. But, even if two people are at the same site at the same time, they don’t see each other. The comment section that a website provides is a tool that we utilise to communicate with it and its users. But this lacks uniformity among websites and looks too simple to be a solution for collaboration.

though collaboration is a natural choice in many situations, there is a lack of specialized tools for seeking information collaboratively. There have been efforts to foster engagement and cooperation in cyberspace, several of which focused on collaborative information-seeking systems (CIS). For instance, Hyldegard \cite{hyldegard_collaborative_2006} employed Kuhlthau’s Information Search Process model \cite{kuhlthau2005towards}, a model created based on single-person knowledge seeking and retrieval, in a study of information seeking and retrieval in a group-based educational context.

In 2009, Shah and his team outlined the design criteria and practical use of a cooperative information-seeking system, based on pilot studies and by collecting feedback from users, called Coagmento \cite{shah_learning_2009}. They formulated design guidelines based on Surowiecki’s \cite{fleenor2006wisdom} four conditions for successful collaboration. They are; (1) diversity of opinion, (2) independence, (3) decentralization, and (4) aggregation. They also took inspiration from Morris and Horvitz’s SearchTogether system \cite{morris2007searchtogether} based on supporting (1) awareness, (2) division of labour, and (3) persistence for collaboration. Based on extensive studies about collaborating tools, they inferred the following set of guidelines for designing a user-centred CIS system.

\begin{itemize}
    \item The system should provide an effective way for users to communicate with each other.
    \item The system should allow (and encourage) each user to make individual contributions to the collaborative.
    \item The system should coordinate user actions, information requests, and responses to support an active and interactive collaboration. This collaboration could be synchronous or asynchronous and co-located or remote.
    \item The system needs to support discussion and negotiation processes among the users.
\end{itemize}

Using the above guidelines, they developed a prototype system called Coagmento that allows two or more people to work together for seeking information. 

The prototype was later implemented as a browser plugin  \cite{gonzalez-ibanez_coagmento_2011} which they made available for popular web browsers like Firefox and Chrome. Along with information collection, sharing and rating, they also implemented communication through PHP free chat\footnote{A simple, fast and customizable chat server which can be easily adapted to projects. Both free and subscription plans are available. Website: http://www.phpfreechat.net/}. The main purpose of this plugin was to collect information from websites by collaborating with other information seekers. It had a complex and old UI. The possibilities of collaborative spam protection and security are not explored. Although it had impressive tools to gather content from websites, it looked too ’academic’ and ’research-oriented’ in nature.

Coagmento v3.0 \cite{soltani_coagmento_2019}, a more recent version of the plugin, confirmed this trend. Rather than a tool for the general public to interact and collaborate, its focus is on research-oriented scenarios. Coagmento intends to increase the efficiency of the information collection process of researchers by serving as a tool for facilitating many of the needs for designing and running a lab study, from executing a session flow to collecting log data\cite{soltani_coagmento_2019}. Several improvements were made to the user interface with additional features like user management, stage editor and questionnaire.

Coagmento’s back end primarily comprises PHP, built on Laravel to create a RESTful framework. The front end is largely custom HTML, CSS, and JavaScript, and the Chrome Extension is also custom. Coagmento can be run locally on a laptop but is intended to run on a remote server so that participants may access it via the web. 

Although Coagmento provides impressive tools for information seeking and collaboration, as said earlier, it is primarily suited for researchers and academicians. Moreover, the possibility of ensuring content quality and the security of the website through collaboration by netizens is not explored. However, the design guidelines and prototypes they provided may be useful in this project to develop a browser plugin that would give visitors a space to interact and a chance to review the quality of the information provided by the website.


\section{check it}

\section{cofind}
\subsection{cofind:A lightweight web browser plugin}

Group awareness is a prominent challenge in the field of co-located collaboration in Multi-display Environments (MDE), where several personal and shared devices are operated simultaneously by multiple users. With a focus on Collaborative Information Seeking (CIS) and particularly different levels of information sharing, our overall goal is to investigate aspects that influence this group awareness as well as the general group performance in such MDE. In this work, we present the conceptual foundation and approach of a research tool, called CoFind. Developed as a lightweight web browser plugin, which connects collaborators by sharing information resources, it provides comprehensive data and activity logging in the context of user studies and their evaluation.Collaboration in co-located working places is assumed to be very productive in terms of direct communication, physical and social interaction. This can even be strengthened by providing appropriate technical equipment, e. g., personal display devices to work simultaneously (division of labor) and large interactive displays to easily share, merge and discuss content., CoFind represents the technical basis for our on-going investigation of the aforementioned questions. Its main purpose is to provide basic means for conducting and observing synchronous, collaborative web search sessions. We furthermore report on a preliminary lab experiment carried out to assess both the feasibility of our general approach and the utility of our developed research prototype. Finally, we also reflect on implications of initial results of this experiment and discuss future research opportunities with regards to co-located collaborative information seeking in MDE.CoFind is a reliable tool for the investigation of group activities in collaborative co-located web search in a MDE.The known issues of using the virtual keyboard with touch display were commented by some subjects. The logging shows the presence and alternation of typical collaborative search phases: individual search and cooperative discussion. Tablets were exclusively used for individual web search and the large shared display was used for discussions and cooperative search. Additionally, individual participants also used more than one device at a time (cross-device). After about half of the processing time the groups started to systematically select and delete bookmarked resources on the shared display device. However, the “activity space” in the sidebar was rarely used during individual search phases, but during joint discussions to quickly retrieve a visited link. The more active usage of shared information indicated the beginning of the discussion phase (about 80% of web pages were opened via shared bookmarks).the actual mode of information sharing plays an important role. While in automatic mode all data is basically shown in real time, it appears to be particularly important for both snapshot and explicit mode to focus on highlighting changes between events.


\section{ml}

\subsection{Machine Learning Techniques for Detection of Website Phishing: A Review for Promises and Challenges}

Websites phishing is a cyber-attack that targets online users to steal their sensitive information including login credentials and banking details. Attackers fool the users by presenting the masked webpage as legitimate or trustworthy to retrieve their essential data. Several solutions to phishing websites attacks have been proposed such as heuristics, blacklist or whitelist, and Machine Learning (ML) based techniques. This paper presents the state of art techniques for phishing website detection using the ML techniques. This research identifies solutions to the website's phishing problem based on ML techniques. The majority of the examined approaches are focused on traditional ML techniques. Random Forest (RF), Support Vector Machine (SVM), Naïve Bayes (NB), and Ada Boosting are the powerful ML techniques examined in the literature.

The paper briefs about different kinds of phishing attacks like spear phishing,clone phishing, whaling etc, and provides an overview of the machine learning-based challenges and techniques.This survey paper also identifies deep learning-based techniques with better performance for detecting phishing websites compared to the conventional ML techniques. Challenges to ML techniques identified in this work includes overfitting, low accuracy, and ML techniques' ineffectiveness in case of unavailability of enough training data. This research suggests that Internet users should know about phishing to avoid cyber-attacks. This paper also points out the proposal for an automated solution to phishing websites.

Phishing attacks present negative impacts on web owners and end-users. The reputation of website owners becomes questionable when attackers launch an attack, and as a result of it, website users lose their sensitive information. This survey paper has revealed information about the advantages of the ML techniques for the detection of phishing websites. Results demonstrated that ML methods are effective in eradicating phishing. However, all phishing-related problems have been not yet resolved by ML techniques. The research and the development of new approaches is an ongoing process as attackers think about new phishing ideas and develop new phishing methods every day.

Phishing cannot be completely eradicated in a day, and due to its pervasiveness, it will not disappear in the near future. Therefore, comprehensive research needs to be undertaken to resolve the website's phishing problem. This paper identifies several challenges to phishing detection and ML-based techniques. The inefficiency of ML techniques on a large amount and images data, and websites with captcha information has been identified. Overfitting, low accuracy, and hyper tuning of ML techniques are widely studied in the literature. The small size of datasets to train the ML techniques is another challenge as identified in this research.

It is also suggested that an automated framework should be proposed based on ensemble learning and deep learning techniques in future works.

\subsection{Phishing Detection Using Machine Learning
Techniques}

The Internet has become an indispensable part of our life, However, It also has provided opportunities to anonymously perform malicious activities like Phishing. Phishers try to deceive their victims by social engineering or creating mockup websites to steal information such as account ID, username, and password from individuals and organizations. Although many methods have been proposed to detect phishing websites, Phishers have evolved their methods to escape from these detection methods. One of the most successful methods for detecting these malicious activities is Machine Learning. This is because most Phishing attacks have some common characteristics which can be identified by machine learning methods.

The paper provide a comparative and analytical evaluation of different machine learning methods on detecting the phishing websites in section I. The machine learning methods that are studied are Logistic Regression, Decision Tree, Random Forest, Ada-Boost, Support Vector Machine, KNN, Artificial Neural Networks, Gradient Boosting, and XGBoost. The rest of the paper is organized as follows: in section II the paper list some widely used phishing techniques which are link manipulation,filter evasion,website forgery,convert redirect,social engineering,etc. in Section III discussion of different types of phishing and phishing attack prevention methods are done.Some of the phishing detection methods explained are list-based approach ,visual similiarity-base approach and machine learning based approach. In section IV an overview of different machine learning methods for phishing detection are provided. In section V  the features of our dataset are illustrated. In section VI and VII  evaluation results of suggested machine learning methods are shown and finally draw conclusions and discuss future works in section VIII.

 This research have implemented and evaluated twelve classifiers on the phishing website dataset that consists of 6157 legitimate websites and 4898 phishing websites.

